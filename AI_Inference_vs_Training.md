# Training: Learning from data (offline)
# - Forward pass + backward pass
# - Updates weights
# - Happens once

# Inference: Using trained model (online)  
# - Forward pass only
# - No weight updates
# - Happens for every request

Training is the computationally intensive process where a model learns from data. 

Gradient computation: The model performs both forward and backward passes. the backward pass computes gradients using backpropogation. calculating how much each parameter should change to minimize loss. 

Parameter updates: Optimizers like Adam SGD or RMSprop adjust model weights based on computed gradients. This requires storing optimizer states, momentum terms, and gradient histories.

Training requires significantly more memory than inference because you need to store model parameters, gradients for each parameter, optimizer states, intermediate activations for backpropogation, input batches(often larger than inference batches)

Inference is the lightweight process of using a trained model to make predicitons: forward only comutation: only the forward pass is executed - no gradient computation or parameter updates occur. 

you only need to store model parameters and intermediate activations for the current forward pass. No gradient or optimizer state storage required.

Optimized for latency, inference systems are optimized for fast response times rather than learning efficiency. Techniques like quantization, pruning, and specialized hardware acceleration are commonly used. 

Stateless operations, each inference call is independent making it easier to parallelize and scale.


Forward pass - the computational pipeline.

Mathematical foundation, the forward pass is a sequence of mathematical transformations that convert input data into predictions.

Input->Linear Transform->Activation->Linear Transform->...->Output

Matrix multiplication the core computational operation. for a linear layer, output = input @ weight + bias

TC: O(n*m*k) for input size n*m and weight matrix m*k

Non linear transformations that enable neural networks to learn complex patterns,  ReLU, GELU, Softmax, Attention.

Computational Graph Execution:

Modern frameworks like PyTorch and Tensorflow build computational graphs.

Static - TF graph defined once, executed repeatedly.
Dynamic - Pytorch graph built on the fly during execution.

Memory management, during inference, intermediate activations can often be discarded immediately after use, unlike training where they must be retained for backpropogation. 

operator fusion: advanced optimizations combine multiple operations(eg matrix multiplication) into single kernels for better performance

Model loading from storage to execution

serialization formats, models are stores in various formats, each with trade offs: 
pytorch files using pickle serialization, 

Standardized formats ,ONNX open neural network exchange cross framework compatibility. 

NVIDIA's optimized format for inference.


Loading process deep dive:

# Typical loading sequence
1. Parse model architecture from metadata
2. Allocate memory for parameters
3. Load weights from storage
4. Initialize compute graphs
5. Move to target device (CPU/GPU)

initialization overhead sources:

Disk I/O: Reading large model files (GPT-4 scale models can be 100GB+)
Memory Copy: Moving weights from system RAM to GPU memory
Graph Compilation: JIT compilation of operations for target hardware
Cache Warming: First few inferences may be slower due to cache misses

Memory layout optimization:
FP32 â†’ FP16: 2x memory reduction, minimal accuracy loss
INT8: 4x reduction, requires careful calibration
INT4/INT2: Aggressive quantization for edge deployment

Memory Mapping: Advanced technique where model weights are mapped directly from disk rather than loaded into RAM, enabling larger models on memory-constrained systems.
Sharding: For very large models, weights are split across multiple devices or storage locations and loaded in parallel.

Inference optimization techniques :

Model level optimization: pruning- removing unnecessary connections or entire neurons: 

Hardware-Specific Optimizations
GPU Optimization:

Tensor Cores: Specialized units for mixed-precision matrix operations
Memory Coalescing: Organizing memory access patterns for maximum bandwidth
Kernel Fusion: Combining operations to reduce memory movement

CPU Optimization:

SIMD Instructions: Single Instruction Multiple Data for parallel processing
Cache-Friendly Access Patterns: Organizing computations to maximize cache hits
Thread Pool Management: Efficiently utilizing multi-core processors

Edge Device Optimization:

Model Compression: Techniques like Huffman coding for weight storage
Dynamic Inference: Adjusting model complexity based on input difficulty
Early Exit Networks: Models that can make predictions at intermediate layers for simple inputs

Batching Strategies
Static Batching: Fixed batch sizes for predictable latency
Dynamic Batching: Variable batch sizes to maximize throughput
Continuous Batching: Advanced technique for autoregressive models like language models
Memory Management
Memory Pooling: Pre-allocating memory to avoid allocation overhead during inference
Gradient Checkpointing: Trading computation for memory by recomputing activations
Activation Compression: Techniques to reduce memory usage of intermediate results
Scaling Considerations
Horizontal Scaling: Multiple model instances across different machines
Vertical Scaling: More powerful hardware for single instances
Model Parallelism: Splitting large models across multiple devices
Pipeline Parallelism: Processing different parts of the model simultaneously



6. Performance Profiling and Bottleneck Analysis
Common Bottlenecks

Memory Bandwidth: Often the limiting factor for large models
Compute Utilization: Ensuring maximum use of available processing power
I/O Latency: Loading model weights and transferring data
Synchronization Overhead: Coordination between parallel processes

Profiling Tools

NVIDIA Nsight: GPU performance analysis
Intel VTune: CPU optimization profiling
Framework Profilers: PyTorch Profiler, TensorFlow Profiler
Custom Metrics: Latency, throughput, memory usage tracking




